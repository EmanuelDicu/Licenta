{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "0dbfc474",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_solution_direct_prompt = \"\"\"\n",
    "You are a C++ programming contest participant. You are given a problem statement and you need to write a C++ program to solve it.\n",
    "- You MUST NOT use any external libraries or functions. You can only use the standard C++ library.\n",
    "- You MUST refrain from adding any extraneous text that is not directly part of or relevant to the solution.\n",
    "- You MUST provide the solution code. Do not include any input/output code or function signature.\n",
    "- You MUST format the content so that it can be enclosed within a triple-quoted string.\n",
    "- You MUST provide only one solution, without any alternative variations.\n",
    "- You MUST wrap the C++ solution code with cpp=>YOUR_SOLUTION_HERE<=cpp tag. The opening tag should be cpp=> and the closing tag should be <=cpp.\n",
    "- You MUST deliver a comprehensive solution, detailing all the necessary steps instead of just presenting the final answer.\n",
    "- You MUST explain the reasoning behind each step, focusing solely on the provided constraints and the problem description.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train covers a distance of x kilometers in y hours. Determine the train's average speed.\n",
    "Objective:\n",
    "Calculate the train's average speed using the given distance and time.\n",
    "Input:\n",
    "On the first line there are two numbers, x (distance in kilometers) and y (time in hours)\n",
    "Output:\n",
    "Print only one number, the average train's speed.\n",
    "\n",
    "Example of test cases:\n",
    "Input: 300 3.5\n",
    "Output: 85.7\n",
    "\n",
    "Solution:\n",
    "Step 1:\n",
    "Read from the input 300 (distance in kilometers) and 3.5 (time in hours)\n",
    "Step 2:\n",
    "To find the average speed, divide the distance by the time: 300 kilometers / 3.5 hours = approximately 85.7 km/h.\n",
    "Step 3:\n",
    "Therefore, the train's average speed is approximately 85.7 km/h.\n",
    "\n",
    "C++ Solution code:\n",
    "cpp=>\n",
    "#include <iostream>\n",
    "\n",
    "int main() {{\n",
    "  // Given values\n",
    "  double distance_km;  // distance traveled in kilometers\n",
    "  double time_hours;   // time taken in hours\n",
    "  \n",
    "  std::cin >> distance_km >> time_hours;\n",
    "\n",
    "  // Calculate the average speed\n",
    "  double average_speed_kmph = distance_km / time_hours;\n",
    "\n",
    "  // Output the average speed\n",
    "  std::cout << average_speed_kmph << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}}\n",
    "<=cpp\n",
    "\n",
    "This is the problem you need to solve:\n",
    "Problem:\n",
    "{Problem}\n",
    "Input:\n",
    "{Input}\n",
    "Output:\n",
    "{Output}\n",
    "C++ solution code:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "get_objective_and_constraints_prompt = \"\"\"\n",
    "Assist me in identifying and examining the primary constraints and the goal of an algorithmic problem.\n",
    "- You MUST extract the constraints directly from the problem statement without making any assumptions or inferences.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST format the constraints as a bullet-point list, with each constraint being formatted using the following format: cns=>YOUR_CONSTRAINT_HERE<=cns\n",
    "- You MUST identify a single, clear objective that has to be surrounded in the following tag: obj=>YOUR_GOAL_HERE<=obj\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "cns=>The train travels a distance of 200 kilometers<=cns\n",
    "cns=>The train travels for 2 hours<=cns\n",
    "Objective:\n",
    "obj=>Calculate the average speed of the train based on the distance traveled and the time taken<=obj\n",
    "\n",
    "Please identify the main constraints and the objective for the following problem:\n",
    "{Problem}\n",
    "\"\"\"\n",
    "\n",
    "get_additional_constraint_prompt = \"\"\"\n",
    "Assist me in deriving an additional constraintfrom an algorithmic problem.\n",
    "- You CAN ONLY use the existing constraints and the problem text to deduce this additional constraint.\n",
    "- You MUST identify a additional constraint that is logically derived from the problem text and the existing constraints.\n",
    "- The additional constraint MUST be relevant to achieving the problem's goal.\n",
    "- Please format the additional constraint in a way that it can be included in a triple-quoted string.\n",
    "- You MUST provide ONLY the additional constraint.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST format the constraint as such: ncns=>YOUR_NEW_CONSTRAINT_HERE<=ncns\n",
    "- IF no additional constraint can be deduced, please provide a message saying ncns=>NONE<=ncns\n",
    "\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Objective:\n",
    "- Calculate the average speed of the train based on the distance traveled and the time taken\n",
    "Additional constraint: \n",
    "ncns=>The average speed of the car is calculated by dividing the distance traveled by the time taken<=ncns\n",
    "\n",
    "Please identify an additional constraint for the following problem:\n",
    "Problem: \n",
    "{Problem}\n",
    "Main constraints: \n",
    "{Constraints}\n",
    "Objective: \n",
    "{Objective}\n",
    "Additional constraint:\n",
    "\"\"\"\n",
    "\n",
    "test_constraint_prompt = \"\"\"\n",
    "Assist me in determining whether an additional constraint is valid for an algorithmic problem.\n",
    "- The constraint is wrapped in the following format: ncns=>CONSTRAINT_TO_BE_VALIDATED<=ncns\n",
    "- You MUST provide a YES or NO as your final answer.\n",
    "- Please format the response so that it can be included in a triple-quoted string.\n",
    "- IF the constraint is valid, it MUST be logically derived from the problem text and the existing constraints.\n",
    "- IF the constraint is true, you MUST respond with YES.\n",
    "- IF the constraint is false, you MUST respond with NO.\n",
    "\n",
    "\n",
    "Here is an example:\n",
    "Problem: \n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Objective:\n",
    "- Calculate the average speed of the train based on the distance traveled and the time taken\n",
    "Constraint to be validated:\n",
    "- The average speed of the car is calculated by dividing the time take by the distance traveled\n",
    "Answer: \n",
    "NO\n",
    "\n",
    "Here is another example:\n",
    "Problem: \n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Objective:\n",
    "- Calculate the average speed of the train based on the distance traveled and the time taken\n",
    "Constraint to be validated:\n",
    "- The average speed of the car is calculated by dividing the distance traveled by the time taken\n",
    "Answer: \n",
    "NO\n",
    "\n",
    "Please test the following constraint for the given problem:\n",
    "Problem:\n",
    "{Problem}\n",
    "Main constraints:\n",
    "{Constraints}\n",
    "Objective:\n",
    "{Objective}\n",
    "Constraint to be validated:\n",
    "{NewConstraint}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "fix_constraint_prompt = \"\"\"\n",
    "Help me revise a constraint derived from an algorithmic problem.\n",
    "- You MUST identify and provide a new constraint that is logically consistent with the problem text.\n",
    "- Please format your response so that it can be included in a triple-quoted string.\n",
    "- The revised constraint MUST be essential for achieving the problem's goal.\n",
    "- You MUST format the revised constraint as such: rcns=>YOUR_REVISED_CONSTRAINT_HERE<=rcns\n",
    "- The revised constraint MUST not duplicate the meaning of the known main constraints.\n",
    "- The revised constraint MUST not be the same as the incorrect constraint, the known constraints, or a rephrased version of either.\n",
    "- You MUST provide ONLY the new, fixed constraint.\n",
    "- If no other constraint can be deduced, you can respond with rcns=>NONE<=rcns\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "The product of two numbers is 24. The first number is twice the second number. What are the numbers?\n",
    "Incorrect constraint:\n",
    "The product of the two numbers is 30.\n",
    "Fixed constraint:\n",
    "rcns=>The product of the two numbers is 24.<=rcns\n",
    "\n",
    "Please fix the following constraint for the given problem:\n",
    "Problem: \n",
    "{Problem}\n",
    "Main constraints:\n",
    "{Constraints}\n",
    "Objective:\n",
    "{Objective}\n",
    "Incorrect constraint: \n",
    "{Incorrect_constraint}\n",
    "Fixed constraint:\n",
    "\"\"\"\n",
    "\n",
    "can_solve_problem_prompt = \"\"\"\n",
    "Help me test if the conditions of a math problem are sufficient to achieve the goal.\n",
    "Please format the text in a such way for it to be able to be included in a triple-quoted string.\n",
    "You MUST provide a YES or NO as your final answer.\n",
    "You MUST answer YES if the conditions are sufficient to achieve the goal.\n",
    "You MUST answer NO if the conditions are NOT sufficient to achieve the goal.\n",
    "Take into account the fact that most problems usually require less than 4 constraints to be solved.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "- The average speed of the car is calculated by dividing the distance traveled by the time taken\n",
    "Objective:\n",
    "- Calculate the average speed of the train based on the distance traveled and the time taken\n",
    "Answer:\n",
    "YES\n",
    "\n",
    "Here is another example:\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Main constraints:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Objective:\n",
    "Calculate the average speed of the train based on the distance traveled and the time taken\n",
    "Answer:\n",
    "NO\n",
    "\n",
    "Please test if the following conditions are sufficient to achieve the goal of the problem:\n",
    "Problem:\n",
    "{Problem}\n",
    "Main constraints:\n",
    "{Constraints}\n",
    "Objective:\n",
    "{Objective}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "generate_solution_MACM_prompt = \"\"\"\n",
    "You are a C++ programing contest participant. You are given a problem statement and the main key points of the solution \n",
    "and also the objective of the problem. Your task is to write a C++ program to solve the problem.\n",
    "- You MUST NOT use any external libraries or functions. You can only use the standard C++ library.\n",
    "- You MUST refrain from adding any extraneous text that is not directly part of or relevant to the solution.\n",
    "- You MUST use the provided constraints and the problem description to derive the solution.\n",
    "- You MUST provide the solution code. Do not include any input/output code or function signature.\n",
    "- You MUST use the provided constraints and the problem description to derive the solution.\n",
    "- You MUST format the content so that it can be enclosed within a triple-quoted string.\n",
    "- You MUST provide only one solution, without any alternative variations.\n",
    "- You MUST wrap the C++ solution code with cpp=>...<=cpp tag.\n",
    "- You MUST deliver a comprehensive solution, detailing all the necessary steps instead of just presenting the final answer.\n",
    "- You MUST explain the reasoning behind each step, focusing solely on the provided constraints and the problem description.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train covers a distance of x kilometers in y hours. Determine the train's average speed.\n",
    "Main constraints:\n",
    "- The train covers a distance of x kilometers\n",
    "- The train covers the distance in y hours\n",
    "- The average speed of the train is calculated by dividing the distance by the time\n",
    "Objective:\n",
    "- Calculate the train's average speed using the given distance and time.\n",
    "Input:\n",
    "On the first line there are two numbers, x (distance in kilometers) and y (time in hours)\n",
    "Output:\n",
    "Print only one number, the average train's speed.\n",
    "\n",
    "Example of test cases:\n",
    "Input: 300 3.5\n",
    "Output: 85.7\n",
    "\n",
    "Solution:\n",
    "Step 1:\n",
    "Read from the input 300 (distance in kilometers) and 3.5 (time in hours)\n",
    "Step 2:\n",
    "To find the average speed, divide the distance by the time: 300 kilometers / 3.5 hours = approximately 85.7 km/h.\n",
    "Step 3:\n",
    "Therefore, the train's average speed is approximately 85.7 km/h.\n",
    "\n",
    "Solution code:\n",
    "cpp=>\n",
    "#include <iostream>\n",
    "\n",
    "int main() {{\n",
    "  // Given values\n",
    "  double distance_km;  // distance traveled in kilometers\n",
    "  double time_hours;   // time taken in hours\n",
    "  \n",
    "  std::cin >> distance_km >> time_hours;\n",
    "\n",
    "  // Calculate the average speed\n",
    "  double average_speed_kmph = distance_km / time_hours;\n",
    "\n",
    "  // Output the average speed\n",
    "  std::cout << average_speed_kmph << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}}\n",
    "<=cpp\n",
    "\n",
    "This is the problem you need to solve:\n",
    "Problem:\n",
    "{Problem}\n",
    "Main constraints:\n",
    "{Constraints}\n",
    "Objective:\n",
    "{Objective}\n",
    "Input:\n",
    "{Input}\n",
    "Output:\n",
    "{Output}\n",
    "C++ solution code:\n",
    "cpp=>YOUR SOLUTION HERE<=cpp\n",
    "\"\"\"\n",
    "\n",
    "get_solution_ToT_prompt = generate_solution_MACM_prompt\n",
    "\n",
    "explain_bullet_points_prompt = \"\"\"\n",
    "Help me explain the key points of a problem statement.\n",
    "- You MUST extract the key points directly from the problem statement.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST format the key points as a bullet-point list, with each point being preceded by a dash.\n",
    "- You MUST provide a comprehensive explanation of the key points.\n",
    "- You MUST NOT include any extraneous text that is not directly part of or relevant to the key points.\n",
    "- You MUST NOT include any information that is not relevant to the problem.\n",
    "- You MUST format the explanation in a way that it can be included in a triple-quoted string.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train covers a distance of x kilometers in y hours. Determine the train's average speed.\n",
    "Calculate the train's average speed using the given distance and time.\n",
    "\n",
    "Key points:\n",
    "- The train covers a distance of x kilometers\n",
    "- The train covers the distance in y hours\n",
    "- The average speed of the train is calculated by dividing the distance by the time\n",
    "\n",
    "Explanation:\n",
    "The problem statement provides the distance covered by the train and the time taken to cover the distance. \n",
    "To calculate the average speed of the train, we divide the distance by the time. This key point is crucial for understanding how to solve the problem.\n",
    "\n",
    "Please explain the key points of the following problem statement:\n",
    "Problem:\n",
    "{Problem}\n",
    "\"\"\"\n",
    "\n",
    "explain_input_output_prompt = \"\"\"\n",
    "Based on your understanding of the problem, explain why for the following input the output is as follows:\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST explain the reasoning behind the input and output relationship.\n",
    "- You MUST NOT include any extraneous text that is not directly part of or relevant to the input and output relationship.\n",
    "- You MUST format the explanation in a way that it can be included in a triple-quoted string.\n",
    "\n",
    "Here are the input and output values:\n",
    "\n",
    "Input1: \n",
    "{Input1}\n",
    "Output1:\n",
    "{Output1}\n",
    "\n",
    "Input2:\n",
    "{Input2}\n",
    "Output2:\n",
    "{Output2}\n",
    "\n",
    "Input3:\n",
    "{Input3}\n",
    "Output3:\n",
    "{Output3}\n",
    "\n",
    "Please explain the relationship between the input and output for each of the provided test cases.\n",
    "\"\"\"\n",
    "\n",
    "generate_starting_solutions_prompt = \"\"\"\n",
    "Based on the key points and the input-output relationship, generate three solutions to the problem in natural language\n",
    "- You MUST NOT provide any solution code.\n",
    "- You MUST generate three different solutions based on the key points and the input-output relationship.\n",
    "- You MUST NOT include any extraneous text that is not directly part of or relevant to the solutions.\n",
    "- You MUST provide a comprehensive explanation of each solution.\n",
    "- You MUST format the solutions in a way that they can be included in a triple-quoted string.\n",
    "- You MUST format the solutions by surrounding them with the following tags: \n",
    "sol1=>YOUR_FIRST_SOLUTION_HERE<=sol1\n",
    "sol2=>YOUR_SECOND_SOLUTION_HERE<=sol2\n",
    "sol3=>YOUR_THIRD_SOLUTION_HERE<=sol3\n",
    "\n",
    "Please generate three different solutions based on the key points and the input-output relationship for the problem\n",
    "\"\"\"\n",
    "\n",
    "gen_final_solution_flow_engineering_prompt = \"\"\"\n",
    "Based on the key points, the input-output relationship, and the generated solutions, pick the best solution and write the C++ code for it.\n",
    "- You MUST pick EXACTLY ONE solution from the generated solutions.\n",
    "- You MUST write the C++ code for the selected solution.\n",
    "- You MUST NOT use any external libraries or functions. You can only use the standard C++ library.\n",
    "- You MUST refrain from adding any extraneous text that is not directly part of or relevant to the solution.\n",
    "- You MUST provide the solution code. Do not include any input/output code or function signature.\n",
    "- You MUST format the content so that it can be enclosed within a triple-quoted string.\n",
    "- You MUST provide only one solution, without any alternative variations.\n",
    "- You MUST wrap the C++ solution code with cpp=>...<=cpp tag.\n",
    "- You MUST deliver a comprehensive solution, detailing all the necessary steps instead of just presenting the final answer.\n",
    "- You MUST explain the reasoning behind each step, focusing solely on the provided constraints and the problem description.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train covers a distance of x kilometers in y hours. Determine the train's average speed.\n",
    "Calculate the train's average speed using the given distance and time.\n",
    "\n",
    "Key points:\n",
    "- The train covers a distance of x kilometers\n",
    "- The train covers the distance in y hours\n",
    "- The average speed of the train is calculated by dividing the distance by the time\n",
    "\n",
    "Solution in natural language:\n",
    "The problem statement provides the distance covered by the train and the time taken to cover the distance.\n",
    "To calculate the average speed of the train, we divide the distance by the time. This key point is crucial for understanding how to solve the problem.\n",
    "\n",
    "\n",
    "Solution code:\n",
    "cpp=>\n",
    "#include <iostream>\n",
    "\n",
    "int main() {{\n",
    "  // Given values\n",
    "  double distance_km;  // distance traveled in kilometers\n",
    "  double time_hours;   // time taken in hours\n",
    "\n",
    "  std::cin >> distance_km >> time_hours;\n",
    "\n",
    "  // Calculate the average speed\n",
    "  double average_speed_kmph = distance_km / time_hours;\n",
    "\n",
    "  // Output the average speed\n",
    "  std::cout << average_speed_kmph << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}}\n",
    "<=cpp\n",
    "\n",
    "Please write the C++ code for the best solution based on the key points, the input-output relationship, and the generated solutions.\n",
    "\"\"\"\n",
    "\n",
    "get_problem_objective_prompt = \"\"\"\n",
    "Help me identify the primary objective of an algorithmic problem.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST extract the primary objective directly from the problem statement.\n",
    "- You MUST NOT include any extraneous text that is not directly part of or relevant to the primary objective.\n",
    "- You MUST format the primary objective by surrounding it with the following tags: obj=>YOUR_OBJECTIVE_HERE<=obj\n",
    "- You MUST write the primary objective in a way that it can be included in a triple-quoted string.\n",
    "\n",
    "Here is an example:\n",
    "Problem\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Objective:\n",
    "obj=>Calculate the average speed of the train based on the distance traveled and the time taken<=obj\n",
    "\n",
    "Please identify the primary objective for the following problem:\n",
    "Problem:\n",
    "{Problem}\n",
    "Objective:\n",
    "\"\"\"\n",
    "\n",
    "get_new_key_point_prompt = \"\"\"\n",
    "Help me find a new key point for an algorithmic problem. I give you the problem statement and a list of existing key points.\n",
    "- You MUST NOT give me any key point that is already in the list of existing key points.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST identify a new key point that is relevant to the problem.\n",
    "- You MUST NOT include any extraneous text that is not directly part of or relevant to the new thought.\n",
    "- You MUST format the new key point by surrounding it with the following tags: key=>YOUR_NEW_KEY_POINT_HERE<=key\n",
    "- You MUST write the key point in a way that it can be included in a triple-quoted string.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "Problem\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Key points:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "New key point:\n",
    "key=>The average speed of the train is calculated by dividing the distance traveled by the time taken<=key\n",
    "\n",
    "Please find a new key point for the following problem:\n",
    "Problem:\n",
    "{Problem}\n",
    "Objective:\n",
    "{Objective}\n",
    "Existing key points:\n",
    "{Key_points}\n",
    "New key point:\n",
    "\"\"\"\n",
    "\n",
    "validate_likelihood_of_key_point_prompt = \"\"\"\n",
    "Help me evaluate the likelihood of a new key point for an algorithmic problem.\n",
    "- You MUST provide a SURE/LIKELY/UNLIKELY/NO as your final answer.\n",
    "- You MUST NOT provide any solution or answer to the problem.\n",
    "- You MUST format the response so that it can be included in a triple-quoted string.\n",
    "- IF the key point is certain, you MUST respond with SURE.\n",
    "- IF the key point is highly probable, you MUST respond with LIKELY.\n",
    "- IF the key point is improbable, you MUST respond with UNLIKELY.\n",
    "- IF the key point is false, you MUST respond with NO.\n",
    "\n",
    "Here is an example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Key points:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Key point to be evaluated:\n",
    "- The average speed of the train is calculated by dividing the distance traveled by the time taken\n",
    "Answer:\n",
    "SURE\n",
    "\n",
    "Here is another example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Key points:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Key point to be evaluated:\n",
    "- The average speed of the car is calculated by dividing the time take by the distance traveled\n",
    "Answer:\n",
    "NO\n",
    "\n",
    "Here is another example:\n",
    "Problem:\n",
    "A train travels 200 kilometers in 2 hours. What is the average speed of the train?\n",
    "Key points:\n",
    "- The train travels a distance of 200 kilometers\n",
    "- The train travels for 2 hours\n",
    "Key point to be evaluated:\n",
    "- The average speed of the car is calculated by dividing one value by the other\n",
    "Answer:\n",
    "LIKELY\n",
    "\n",
    "Please evaluate the likelihood of the following key point for the given problem:\n",
    "Problem:\n",
    "{Problem}\n",
    "Objective:\n",
    "{Objective}\n",
    "Key points:\n",
    "{Key_points}\n",
    "Key point to be evaluated:\n",
    "{Eval_key_point}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T21:48:38.360071Z",
     "start_time": "2024-08-17T21:48:32.323981Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from typing import cast\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "\n",
    "openai_client = OpenAI(api_key=\"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\")\n",
    "llama_client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key=\"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\")\n",
    "\n",
    "deepmind_ds: DatasetDict = cast(DatasetDict, load_dataset(\"deepmind/code_contests\"))\n",
    "with open('datasets/usaco_subset307_dict.json', 'r') as f:\n",
    "  usaco_ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "eee03cd6144969f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:24:43.144252Z",
     "start_time": "2024-08-16T05:24:43.124640Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_usaco_tests(problem_id, num_tests):\n",
    "  test_cases = []\n",
    "  test_folder = f\"./datasets/usaco_v3/tests/{problem_id}\"\n",
    "  for i in range(1, 11):\n",
    "    for (input_path, output_path) in [(f\"{test_folder}/I.{i}\", f\"{test_folder}/O.{i}\"), \n",
    "                                      (f\"{test_folder}/{i}.in\", f\"{test_folder}/{i}.out\")]:\n",
    "      if not os.path.isfile(input_path) or not os.path.isfile(output_path):\n",
    "        continue\n",
    "      with open(input_path, 'r') as f:\n",
    "        input_data = f.read()\n",
    "      with open(output_path, 'r') as f:\n",
    "        output_data = f.read()\n",
    "      test_cases.append({\n",
    "        \"input\": input_data,\n",
    "        \"output\": output_data\n",
    "      })\n",
    "  test_cases = sorted(test_cases, key=lambda x: len(x[\"input\"]))[:num_tests]\n",
    "  return test_cases\n",
    "\n",
    "def parse_usaco_ds(num_problems, difficulty, num_tests):\n",
    "  usaco_problems = []\n",
    "  for key in usaco_ds.keys():\n",
    "    if len(usaco_problems) >= num_problems:\n",
    "      break\n",
    "    problem = usaco_ds[key]\n",
    "    if problem[\"problem_level\"] != difficulty:\n",
    "      continue\n",
    "    \n",
    "    usaco_problems.append({\n",
    "      \"name\": problem[\"name\"].replace(\" \", \"_\"),\n",
    "      \"description\": problem[\"description\"],\n",
    "      \"tests\": parse_usaco_tests(problem[\"problem_id\"], num_tests)\n",
    "    })\n",
    "  \n",
    "  return usaco_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "5f8fb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_deepmind_tests(problem, num_tests):\n",
    "  test_cases = []\n",
    "  for test_set in [problem[\"public_tests\"], problem[\"generated_tests\"], problem[\"private_tests\"]]:\n",
    "    for input_test, output_test in zip(test_set[\"input\"], test_set[\"output\"]):\n",
    "      test_cases.append({\n",
    "        \"input\": input_test,\n",
    "        \"output\": output_test\n",
    "      })\n",
    "  test_cases = sorted(test_cases, key=lambda x: len(x[\"input\"]))[:num_tests]\n",
    "  return test_cases\n",
    "\n",
    "def parse_deepmind_ds(num_problems, min_rating, max_rating, num_tests):\n",
    "  deepmind_problems = []\n",
    "  for problem in cast(dict, deepmind_ds['train']):\n",
    "    if len(deepmind_problems) >= num_problems:\n",
    "      break\n",
    "    if problem[\"cf_rating\"] < min_rating or problem[\"cf_rating\"] > max_rating:\n",
    "      continue\n",
    "    deepmind_problems.append({\n",
    "      \"name\": problem[\"name\"].replace(\" \", \"_\"),\n",
    "      \"description\": problem[\"description\"],\n",
    "      \"tests\": parse_deepmind_tests(problem, num_tests),\n",
    "    })\n",
    "    \n",
    "  return deepmind_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "ec37774c7ced0e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:24:09.916642Z",
     "start_time": "2024-08-16T05:24:09.903634Z"
    }
   },
   "outputs": [],
   "source": [
    "class CompilationError():\n",
    "  def __init__(self, message):\n",
    "    self.message = message\n",
    "\n",
    "class CompilationSuccess():\n",
    "  pass\n",
    "\n",
    "class RuntimeError():\n",
    "  def __init__(self, message):\n",
    "    self.message = message\n",
    "\n",
    "class RunSuccess():\n",
    "  def __init__(self, output):\n",
    "    self.output = output\n",
    "\n",
    "class TestFailed():\n",
    "  def __init__(self, message, input, expected_output, output, number_of_tests, tests_passed):\n",
    "    self.message = message\n",
    "    self.input = input\n",
    "    self.expected_output = expected_output\n",
    "    self.output = output\n",
    "    self.number_of_tests = number_of_tests\n",
    "    self.tests_passed = tests_passed\n",
    "\n",
    "class TestSuccess():\n",
    "  def __init__(self, message, number_of_tests):\n",
    "    self.message = message\n",
    "    self.number_of_tests = number_of_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "5b3fe2f8d4ceec90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:24:16.239002Z",
     "start_time": "2024-08-16T05:24:16.235872Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_cpp(strategy, model, problem, solution_code):\n",
    "  task_name = problem[\"name\"]\n",
    "  \n",
    "  folder = f\"generated/{strategy}/{model}/{task_name}\"\n",
    "  os.makedirs(folder, exist_ok=True)\n",
    "  if os.path.exists(f\"{folder}/{task_name}.cpp\"):\n",
    "    os.remove(f\"{folder}/{task_name}.cpp\")\n",
    "  if os.path.exists(f\"{folder}/{task_name}\"):\n",
    "    os.remove(f\"{folder}/{task_name}\")\n",
    "    \n",
    "  with open(f\"{folder}/{task_name}.cpp\", \"w\") as f:\n",
    "    f.write(solution_code)\n",
    "    compile_command = [\"g++\", f\"{folder}/{task_name}.cpp\", \"-o\", f\"{folder}/{task_name}\"]\n",
    "\n",
    "  result = subprocess.run(compile_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  if result.returncode != 0:\n",
    "    with open(f\"{folder}/compilation_error.txt\", \"w\") as f:\n",
    "      f.write(result.stderr.decode('utf-8'))\n",
    "\n",
    "    return CompilationError(f\"Compilation failed: {result.stderr.decode('utf-8')}\")\n",
    "  return CompilationSuccess()\n",
    "\n",
    "def get_compilation_report(strategy, model, problem, messages, content):\n",
    "  start = content.find(\"cpp=>\")\n",
    "  end = content.find(\"<=cpp\")\n",
    "\n",
    "  if start == -1 or end == -1:\n",
    "    messages.append({\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"You MUST provide the solution code in the format of cpp=>YOUR SOLUTION HERE<=cpp.\"\n",
    "    })\n",
    "    return None\n",
    "\n",
    "  solution_code = content[start+5:end]\n",
    "  \n",
    "  r = compile_cpp(strategy, model, problem, solution_code)\n",
    "  if r.__class__.__name__ == \"CompilationError\":\n",
    "    messages.append({\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Compilation failed. Please correct the errors and try again.\\\n",
    "                  \\n\\nError message: {}\".format(r.message)\n",
    "    })\n",
    "    return None\n",
    "\n",
    "  return solution_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "b11a41b7c03aad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemOutput:\n",
    "  def __init__(self, passed_tests, rte_tests, failed_tests, solution_code):\n",
    "    self.passed_tests = passed_tests\n",
    "    self.rte_tests = rte_tests\n",
    "    self.failed_tests = failed_tests\n",
    "    self.solution_code = solution_code\n",
    "    \n",
    "def run_program(executable, input_data):\n",
    "  process = subprocess.Popen([f\"./{executable}\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  output, error = process.communicate(input=input_data.encode())\n",
    "  if process.returncode != 0:\n",
    "    return RuntimeError(f\"Runtime error: {error.decode('utf-8')}\")\n",
    "  return RunSuccess(output.decode('utf-8'))\n",
    "\n",
    "def get_runtime_report(strategy, model, problem, solution_code):\n",
    "  task_name = problem[\"name\"]\n",
    "  \n",
    "  passed_tests = []\n",
    "  rte_tests = []\n",
    "  failed_tests = []\n",
    "\n",
    "  for test_case in problem[\"tests\"]:\n",
    "    input_data = test_case[\"input\"]\n",
    "    expected_output = test_case[\"output\"]\n",
    "\n",
    "    output = run_program(f\"generated/{strategy}/{model}/{task_name}/{task_name}\", input_data)\n",
    "    if output.__class__.__name__ == \"RuntimeError\":\n",
    "      rte_tests.append({\n",
    "        \"input\": input_data,\n",
    "        \"output\": expected_output,\n",
    "        \"error\": output.message\n",
    "      })\n",
    "    elif output.__class__.__name__ == \"RunSuccess\" and output.output.strip() == expected_output.strip():\n",
    "      passed_tests.append({\n",
    "        \"input\": input_data,\n",
    "        \"output\": expected_output\n",
    "      })\n",
    "    else:\n",
    "      failed_tests.append({\n",
    "        \"input\": input_data,\n",
    "        \"expected_output\": expected_output,\n",
    "        \"actual_output\": output.output\n",
    "      })\n",
    "      \n",
    "  return ProblemOutput(passed_tests, rte_tests, failed_tests, solution_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "a56256c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ai(model, messages):\n",
    "  if model == \"meta/llama3-70b-instruct\":\n",
    "    client = llama_client\n",
    "  else:\n",
    "    client = openai_client\n",
    "    \n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=messages\n",
    "    )\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    content = response.choices[0].message.content\n",
    "  except Exception:\n",
    "    # sleep\n",
    "    time.sleep(60)\n",
    "    \n",
    "    try:\n",
    "      response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "      )\n",
    "      messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "      content = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      # rethrow the original exception\n",
    "      raise e\n",
    "    \n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "48dabfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_messages(strategy, model, problem, messages):\n",
    "  task_name = problem[\"name\"]\n",
    "  log_folder = f\"generated/{strategy}/{model}/{task_name}\"\n",
    "  log_file_path = f\"{log_folder}/log.txt\"\n",
    "  mode = \"a\" if os.path.isfile(log_file_path) else \"w\"\n",
    "\n",
    "  os.makedirs(log_folder, exist_ok=True)\n",
    "  with open(log_file_path, mode) as f:\n",
    "    for message in messages:\n",
    "      f.write(f\"{message['role']}:\\n\\n{message['content']}\\n{'-'*100}\\n\")\n",
    "\n",
    "  \n",
    "def log_report(strategy, model, problem, report):\n",
    "  task_name = problem[\"name\"]\n",
    "  log_folder = f\"generated/{strategy}/{model}/{task_name}\"\n",
    "\n",
    "  os.makedirs(log_folder, exist_ok=True)\n",
    "  with open(f\"{log_folder}/report.txt\", \"w\") as f:\n",
    "    f.write(\"Passed tests: {}\\n\".format(len(report.passed_tests)))\n",
    "    f.write(\"Runtime error tests: {}\\n\".format(len(report.rte_tests)))\n",
    "    f.write(\"Failed tests: {}\\n\".format(len(report.failed_tests)))\n",
    "    f.write(\"Total tests: {}\\n\".format(len(problem[\"tests\"])))\n",
    "    f.write(\"Solution code:\\n\\n{}\\n\".format(report.solution_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "2d893f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpp_code(strategy, model, problem, messages):\n",
    "  best_output = None\n",
    "  trials_since_last_solution = 0\n",
    "\n",
    "  for _ in range(10):\n",
    "    content = call_ai(model, messages)\n",
    "    \n",
    "    source_code = get_compilation_report(strategy, model, problem, messages, content)\n",
    "    if source_code is None:\n",
    "      continue\n",
    "\n",
    "    run_report = get_runtime_report(strategy, model, problem, source_code)\n",
    "    if best_output is None or len(run_report.passed_tests) > len(best_output.passed_tests):\n",
    "      best_output = run_report\n",
    "      trials_since_last_solution = 0\n",
    "      \n",
    "      if len(run_report.passed_tests) == len(problem[\"tests\"]):\n",
    "        break\n",
    "    else:\n",
    "      trials_since_last_solution += 1\n",
    "      if trials_since_last_solution >= 4:\n",
    "        messages.append({\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"You MUST start again from your last best solution and try to improve it by fixing the failed tests.\\\n",
    "                      \\nYour last best solution is:\\n\\n{}\".format(best_output.solution_code)\n",
    "        })\n",
    "  \n",
    "  log_messages(strategy, model, problem, messages)\n",
    "  log_report(strategy, model, problem, best_output)\n",
    "  return best_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "c9c9f8e5d1da415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution_direct_prompting(problem, model):\n",
    "  strategy = \"direct_prompting\"\n",
    "  description = problem[\"description\"]\n",
    "  public_test = problem[\"tests\"][0]\n",
    "  \n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": generate_solution_direct_prompt.format(Problem=description, Input=public_test[\"input\"], Output=public_test[\"output\"])\n",
    "  }]\n",
    "  return get_cpp_code(strategy, model, problem, messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "00dca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_and_constraints(strategy, model, problem):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": get_objective_and_constraints_prompt.format(Problem=problem[\"description\"])\n",
    "  }]\n",
    "\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "\n",
    "  # find constraints\n",
    "  constraints = []\n",
    "  start = 0\n",
    "  while True:\n",
    "    start = content.find(\"cns=>\", start)\n",
    "    if start == -1:\n",
    "      break\n",
    "    end = content.find(\"<=cns\", start)\n",
    "    constraints.append(content[start+5:end])\n",
    "    start = end\n",
    "  \n",
    "  start = content.find(\"obj=>\")\n",
    "  end = content.find(\"<=obj\")\n",
    "  objective = content[start+5:end]\n",
    "\n",
    "  return constraints, objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "7d13597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_constraint(strategy, model, problem, constraints, objective):\n",
    "  messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": get_additional_constraint_prompt.format(Problem=problem[\"description\"], \n",
    "      Constraints=\"\\n\".join([\"- \" + c for c in constraints]), Objective=\"- \" + objective)\n",
    "  }]\n",
    "\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "\n",
    "  start = content.find(\"ncns=>\")\n",
    "  end = content.find(\"<=ncns\")\n",
    "  additional_constraint = content[start+6:end].strip()\n",
    "\n",
    "  return additional_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "id": "bec2049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_constraint(strategy, model, problem, constraints, objective, additional_constraint):\n",
    "  if additional_constraint == \"NONE\":\n",
    "    return False\n",
    "  \n",
    "  cnt_yes = 0\n",
    "  for _ in range(3):\n",
    "    messages = [{\n",
    "      \"role\": \"user\",\n",
    "      \"content\": test_constraint_prompt.format(Problem=problem[\"description\"], \n",
    "        Constraints=\"\\n\".join([\"- \" + c for c in constraints]), Objective=\"- \" + objective, NewConstraint=additional_constraint)\n",
    "    }]\n",
    "    content = call_ai(model, messages)\n",
    "    log_messages(strategy, model, problem, messages)\n",
    "    \n",
    "    start = content.find(\"Answer:\")\n",
    "    end = content.find(\"```\", start)\n",
    "    answer = content[start+8:end].strip()\n",
    "    if answer == \"YES\":\n",
    "      cnt_yes += 1\n",
    "    if cnt_yes == 2:\n",
    "      return True\n",
    "    \n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "2edda9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_constraint(strategy, model, problem, constraints, objective, incorrect_constraint):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": fix_constraint_prompt.format(Problem=problem[\"description\"], \n",
    "      Constraints=\"\\n\".join([\"- \" + c for c in constraints]), Objective=\"- \" + objective, Incorrect_constraint=incorrect_constraint)\n",
    "  }]\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "\n",
    "  start = content.find(\"rcns=>\")\n",
    "  end = content.find(\"<=rcns\")\n",
    "  fixed_constraint = content[start+6:end].strip()\n",
    "  \n",
    "  return fixed_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "83a17112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_solve_problem(strategy, model, problem, constraints, objective):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": can_solve_problem_prompt.format(Problem=problem[\"description\"], \n",
    "      Constraints=\"\\n\".join([\"- \" + c for c in constraints]), Objective=\"- \" + objective)\n",
    "  }]\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "\n",
    "  # find answer\n",
    "  start = content.find(\"Answer:\")\n",
    "  end = content.find(\"```\", start)\n",
    "  answer = content[start+8:end].strip()\n",
    "\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "ad366672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution_MACM(problem, model):\n",
    "  strategy = \"MACM\"\n",
    "  description = problem[\"description\"]\n",
    "  public_test = problem[\"tests\"][0]\n",
    "\n",
    "  constraints, objective = get_objective_and_constraints(strategy, model, problem)\n",
    "  for _ in range(5):\n",
    "    additional_constraint = get_additional_constraint(strategy, model, problem, constraints, objective)\n",
    "    if not is_valid_constraint(strategy, model, problem, constraints, objective, additional_constraint):\n",
    "      additional_constraint = fix_constraint(strategy, model, problem, constraints, objective, additional_constraint)\n",
    "      if additional_constraint != \"NONE\":\n",
    "        constraints.append(additional_constraint)\n",
    "    if can_solve_problem(strategy, model, problem, constraints, objective):\n",
    "      break\n",
    "\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": generate_solution_MACM_prompt.format(Problem=description,\n",
    "      Constraints=\"\\n\".join([\"- \" + c for c in constraints]), Objective=\"- \" + objective, Input=public_test[\"input\"], Output=public_test[\"output\"])\n",
    "  }]\n",
    "\n",
    "  return get_cpp_code(strategy, model, problem, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "bf634513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution_flow_engineering(problem, model):\n",
    "  strategy = \"flow_engineering\"\n",
    "\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": explain_bullet_points_prompt.format(Problem=problem[\"description\"])\n",
    "  }]\n",
    "  call_ai(model, messages)\n",
    "\n",
    "  messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": explain_input_output_prompt.format(\n",
    "      Input1=problem[\"tests\"][0][\"input\"], Output1=problem[\"tests\"][0][\"output\"],\n",
    "      Input2=problem[\"tests\"][1][\"input\"], Output2=problem[\"tests\"][1][\"output\"],\n",
    "      Input3=problem[\"tests\"][2][\"input\"], Output3=problem[\"tests\"][2][\"output\"],\n",
    "    )\n",
    "  })\n",
    "  call_ai(model, messages)\n",
    "\n",
    "  messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": generate_starting_solutions_prompt\n",
    "  })\n",
    "  call_ai(model, messages)\n",
    "\n",
    "  messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": gen_final_solution_flow_engineering_prompt\n",
    "  })\n",
    "  return get_cpp_code(strategy, model, problem, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "4ce55e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_for_problem(strategy, model, problem):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": get_problem_objective_prompt.format(Problem=problem[\"description\"])\n",
    "  }]\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "  \n",
    "  start = content.find(\"obj=>\")\n",
    "  end = content.find(\"<=obj\")\n",
    "  objective = content[start+5:end]\n",
    "\n",
    "  return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "054e297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_key_point(strategy, model, problem, objective, key_points):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": get_new_key_point_prompt.format(Problem=problem[\"description\"], \n",
    "      Objective=objective, Key_points=\"\\n\".join([\"- \" + kp for kp in key_points]))\n",
    "  }]\n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "  \n",
    "  start = content.find(\"key=>\")\n",
    "  end = content.find(\"<=key\")\n",
    "  new_key_point = content[start+5:end]\n",
    "\n",
    "  return new_key_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "fc81fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_likelyhood_of_key_point(strategy, model, problem, objective, key_points, eval_key_point):\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": validate_likelihood_of_key_point_prompt.format(Problem=problem[\"description\"], \n",
    "      Objective=objective, Key_points=\"\\n\".join([\"- \" + kp for kp in key_points]), Eval_key_point=eval_key_point)\n",
    "  }]    \n",
    "  content = call_ai(model, messages)\n",
    "  log_messages(strategy, model, problem, messages)\n",
    "\n",
    "  start = content.find(\"Answer:\")\n",
    "  end = content.find(\"```\", start)\n",
    "  answer = content[start+8:end].strip()\n",
    "\n",
    "  return answer\n",
    "\n",
    "def get_node_score(strategy, model, problem, objective, key_points, eval_key_point):\n",
    "  score = 0.0\n",
    "  trials = 1\n",
    "  for _ in range(trials):\n",
    "    answer = validate_likelyhood_of_key_point(strategy, model, problem, objective, key_points, eval_key_point)\n",
    "    if answer == \"SURE\":\n",
    "      score += 1.0\n",
    "    elif answer == \"LIKELY\":\n",
    "      score += 0.5\n",
    "    elif answer == \"UNLIKELY\":\n",
    "      score -= 0.5\n",
    "    elif answer == \"NO\":\n",
    "      score -= 1.0\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "5301b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThoughtNode:\n",
    "  def __init__(self, key_points):\n",
    "    self.key_points = key_points\n",
    "\n",
    "def get_solution_tree_of_thoughts(model, problem):\n",
    "  strategy = \"ToT\"\n",
    "  public_test = problem[\"tests\"][0]\n",
    "  get_solution_ToT_prompt = generate_solution_MACM_prompt\n",
    "  objective = get_objective_for_problem(strategy, model, problem)\n",
    "  current_level_nodes = [ThoughtNode([])]\n",
    "\n",
    "  for _ in range(3):\n",
    "    new_level_nodes = []\n",
    "    for node in current_level_nodes:\n",
    "      for _ in range(3):\n",
    "        new_key_point = get_new_key_point(strategy, model, problem, objective, node.key_points)\n",
    "        new_level_nodes.append(ThoughtNode(node.key_points + [new_key_point]))\n",
    "    current_level_nodes = sorted(new_level_nodes, key=lambda x: \n",
    "      get_node_score(strategy, model, problem, objective, x.key_points[:-1], x.key_points[-1]), reverse=True)[:3]\n",
    "\n",
    "  key_points = []\n",
    "  for node in current_level_nodes:\n",
    "    key_points += node.key_points\n",
    "\n",
    "  messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": get_solution_ToT_prompt.format(Problem=problem[\"description\"], \n",
    "      Constraints=\"\\n\".join([\"- \" + c for c in key_points]), Objective=\"- \" + objective, Input=public_test[\"input\"], Output=public_test[\"output\"])\n",
    "  }]\n",
    "\n",
    "  return get_cpp_code(strategy, model, problem, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "25b4098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_log_folder(strategy, model, problem):\n",
    "  task_name = problem[\"name\"]\n",
    "  log_folder = f\"generated/{strategy}/{model}/{task_name}\"\n",
    "  if not os.path.exists(log_folder):\n",
    "    return\n",
    "  for file in os.listdir(log_folder):\n",
    "    os.remove(f\"{log_folder}/{file}\")\n",
    "  os.rmdir(log_folder)\n",
    "  \n",
    "def parse_log_folder(strategy, model, problem):\n",
    "  task_name = problem[\"name\"]\n",
    "  log_folder = f\"generated/{strategy}/{model}/{task_name}\"\n",
    "  if not os.path.exists(log_folder):\n",
    "    return None\n",
    "\n",
    "  report_file = f\"{log_folder}/report.txt\"\n",
    "  if not os.path.isfile(report_file):\n",
    "    return None\n",
    "\n",
    "  with open(report_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    passed_tests = int(lines[0].split(\":\")[1].strip())\n",
    "    rte_tests = int(lines[1].split(\":\")[1].strip())\n",
    "    failed_tests = int(lines[2].split(\":\")[1].strip())\n",
    "    solution_code = \"\".join(lines[6:])\n",
    "    \n",
    "  return ProblemOutput(passed_tests, rte_tests, failed_tests, solution_code)\n",
    "\n",
    "def get_solution(strategy, model, problem, should_remove_folder = False):\n",
    "  if should_remove_folder:\n",
    "    remove_log_folder(strategy, model, problem)\n",
    " \n",
    "  answer = parse_log_folder(strategy, model, problem)\n",
    "  \n",
    "  if answer is not None:\n",
    "    return answer\n",
    "  elif strategy == \"direct_prompting\":\n",
    "    return get_solution_direct_prompting(model, problem)\n",
    "  elif strategy == \"MACM\":\n",
    "    return get_solution_MACM(model, problem)\n",
    "  elif strategy == \"flow_engineering\":\n",
    "    return get_solution_flow_engineering(model, problem)\n",
    "  elif strategy == \"ToT\":\n",
    "    return get_solution_tree_of_thoughts(model, problem)\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "dc5b0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepmind_easy_problems = parse_deepmind_ds(num_problems=10, min_rating=0, max_rating=1400, num_tests=10)\n",
    "deepmind_medium_problems = parse_deepmind_ds(num_problems=10, min_rating=1400, max_rating=2000, num_tests=10)\n",
    "deepmind_hard_problems = parse_deepmind_ds(num_problems=10, min_rating=2000, max_rating=3000, num_tests=10)\n",
    "\n",
    "usaco_easy_problems = parse_usaco_ds(num_problems=10, difficulty=\"bronze\", num_tests=10)\n",
    "usaco_medium_problems = parse_usaco_ds(num_problems=10, difficulty=\"silver\", num_tests=10)\n",
    "usaco_hard_problems = parse_usaco_ds(num_problems=10, difficulty=\"gold\", num_tests=10)\n",
    "\n",
    "strategies = [\"direct_prompting\", \"MACM\", \"flow_engineering\", \"ToT\"]\n",
    "models = [\"gpt-3.5-turbo\", \"gpt-4o-mini\", \"meta/llama3-70b-instruct\"]\n",
    "\n",
    "problem_labels = ['DeepMind <= 1400', 'DeepMind <= 2000', 'DeepMind <= 3000', 'USACO Bronze', 'USACO Silver', 'USACO Gold']  \n",
    "problem_datasets = [deepmind_easy_problems, deepmind_medium_problems, deepmind_hard_problems, usaco_easy_problems, usaco_medium_problems, usaco_hard_problems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "e0ae9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_distribution_pie_chart():\n",
    "  sizes = [len(deepmind_easy_problems), len(deepmind_medium_problems), len(deepmind_hard_problems), \n",
    "           len(usaco_easy_problems), len(usaco_medium_problems), len(usaco_hard_problems)]\n",
    "  colors = ['red', 'blue', 'green', 'orange', 'purple', 'yellow']\n",
    "\n",
    "  labels = problem_labels.copy()\n",
    "  for i, size in enumerate(sizes):\n",
    "    labels[i] += f\"\\n{size} probleme\"\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.pie(sizes, labels=labels, colors=colors)\n",
    "  ax.axis('equal')\n",
    "  \n",
    "  os.makedirs(\"statistics\", exist_ok=True)\n",
    "  plt.savefig(\"statistics/problem_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "08c87e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_model_passed_test_rate_stackbar(strategy, model, problem_datasets):\n",
    "  passed_test_rates = []  \n",
    "  for problem_dataset in problem_datasets:\n",
    "    passed_test_rate = 0.0\n",
    "    for problem in problem_dataset:\n",
    "      solution = get_solution(strategy, model, problem)\n",
    "      passed_test_rate += len(solution.passed_tests) / len(problem[\"tests\"])\n",
    "    passed_test_rate /= len(problem_dataset)\n",
    "    passed_test_rates.append(passed_test_rate)\n",
    "    \n",
    "  fig, ax = plt.subplots()\n",
    "  ax.bar(range(len(passed_test_rates)), passed_test_rates)\n",
    "  ax.set_xticks(range(len(passed_test_rates)))\n",
    "  ax.set_xticklabels(problem_labels)\n",
    "  ax.set_ylabel('Success rate')\n",
    "  ax.set_title(f'Success rate for {strategy} using {model}')\n",
    "  \n",
    "  os.makedirs(\"statistics\", exist_ok=True)\n",
    "  plt.savefig(f\"statistics/{strategy}_{model}_passed_test_rate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "8570046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_model_success_rate_heatmap(strategies, models, problem_dataset):\n",
    "  success_rates = []\n",
    "  for strategy in strategies:\n",
    "    success_rates.append([])\n",
    "    for model in models:\n",
    "      success_rate = 0\n",
    "      for problem in problem_dataset:\n",
    "        solution = get_solution(strategy, model, problem)\n",
    "        if len(solution.passed_tests) / len(problem[\"tests\"]) >= 0.8:\n",
    "          success_rate += 1\n",
    "      success_rate /= len(problem_dataset)\n",
    "      success_rates[-1].append(success_rate)\n",
    "      \n",
    "  fig, ax = plt.subplots()\n",
    "  im = ax.imshow(success_rates)\n",
    "  \n",
    "  ax.set_xticks(range(len(models)))\n",
    "  ax.set_yticks(range(len(strategies)))\n",
    "  ax.set_xticklabels(models)\n",
    "  ax.set_yticklabels(strategies)\n",
    "  \n",
    "  for i in range(len(strategies)):\n",
    "    for j in range(len(models)):\n",
    "      text = ax.text(j, i, success_rates[i][j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "      \n",
    "  os.makedirs(\"statistics\", exist_ok=True)\n",
    "  plt.savefig(\"statistics/{problem_dataset}_success_rate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "e78db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dataset_success_of_strategy_polyline_chart(strategies, model, problem_datasets):  \n",
    "  fig, ax = plt.subplots()    \n",
    "  \n",
    "  for strategy in strategies:\n",
    "    success_rates = []\n",
    "    for problem_dataset in problem_datasets:\n",
    "      success_rate = 0\n",
    "      for problem in problem_dataset:\n",
    "        solution = get_solution(strategy, model, problem)\n",
    "        if len(solution.passed_tests) / len(problem[\"tests\"]) >= 0.8:\n",
    "          success_rate += 1\n",
    "      success_rate /= len(problem_dataset)\n",
    "      success_rates.append(success_rate)\n",
    "      \n",
    "    ax.plot(range(len(problem_datasets)), success_rates, label=strategy)\n",
    "    \n",
    "  ax.set_xticks(range(len(problem_datasets)))\n",
    "  ax.set_xticklabels(problem_labels)\n",
    "  ax.set_ylabel('Success rate')\n",
    "  \n",
    "  ax.legend()\n",
    "  \n",
    "  os.makedirs(\"statistics\", exist_ok=True)\n",
    "  plt.savefig(f\"statistics/{model}_success_rate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "8d3c6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_deepmind_problems = parse_deepmind_ds(num_problems=1, min_rating=0, max_rating=1400, num_tests=10)\n",
    "\n",
    "dummy_strategies = [\"direct_prompting\", \"MACM\", \"flow_engineering\", \"ToT\"]\n",
    "dummy_models = [\"gpt-3.5-turbo\"]\n",
    "\n",
    "dummy_problem_labels = ['DeepMind <= 1400']\n",
    "dummy_problem_datasets = [dummy_deepmind_problems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "3fe55eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem_distribution_pie_chart()\n",
    "\n",
    "# for strategy in dummy_strategies:\n",
    "#   for model in dummy_models:\n",
    "#     strategy_model_passed_test_rate_stackbar(strategy, model, dummy_problem_datasets)\n",
    "    \n",
    "# for problem_dataset in dummy_problem_labels:\n",
    "#   strategy_model_success_rate_heatmap(dummy_strategies, dummy_models, dummy_problem_datasets[dummy_problem_labels.index(problem_dataset)])\n",
    "  \n",
    "# for model in dummy_models:\n",
    "#   model_dataset_success_of_strategy_polyline_chart(dummy_strategies, model, dummy_problem_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
